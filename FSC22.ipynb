{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"cjC1xZewA9Q9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711139317155,"user_tz":-330,"elapsed":96651,"user":{"displayName":"Tanishq Trivedi","userId":"08401598246083797041"}},"outputId":"a27a6197-4808-4e9a-b648-45d778995fb0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting timm\n","  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.2.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.1+cu121)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.3)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.3)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->timm)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->timm)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->timm)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->timm)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->timm)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->timm)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->timm)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->timm)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->timm)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->timm)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->timm)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->timm)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 timm-0.9.16\n","Collecting torchattacks\n","  Downloading torchattacks-3.5.1-py3-none-any.whl (142 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (2.2.1+cu121)\n","Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (0.17.1+cu121)\n","Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (1.11.4)\n","Requirement already satisfied: tqdm>=4.56.1 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (4.66.2)\n","Collecting requests~=2.25.1 (from torchattacks)\n","  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (1.25.2)\n","Collecting chardet<5,>=3.0.2 (from requests~=2.25.1->torchattacks)\n","  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting idna<3,>=2.5 (from requests~=2.25.1->torchattacks)\n","  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests~=2.25.1->torchattacks)\n","  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.25.1->torchattacks) (2024.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.1->torchattacks) (12.4.99)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.8.2->torchattacks) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.1->torchattacks) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.1->torchattacks) (1.3.0)\n","Installing collected packages: urllib3, idna, chardet, requests, torchattacks\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 2.0.7\n","    Uninstalling urllib3-2.0.7:\n","      Successfully uninstalled urllib3-2.0.7\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.6\n","    Uninstalling idna-3.6:\n","      Successfully uninstalled idna-3.6\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 5.2.0\n","    Uninstalling chardet-5.2.0:\n","      Successfully uninstalled chardet-5.2.0\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.31.0\n","    Uninstalling requests-2.31.0:\n","      Successfully uninstalled requests-2.31.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","bigframes 0.26.0 requires requests>=2.27.1, but you have requests 2.25.1 which is incompatible.\n","google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.25.1 which is incompatible.\n","tweepy 4.14.0 requires requests<3,>=2.27.0, but you have requests 2.25.1 which is incompatible.\n","yfinance 0.2.37 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed chardet-4.0.0 idna-2.10 requests-2.25.1 torchattacks-3.5.1 urllib3-1.26.18\n"]}],"source":["\"\"\"libraries required\"\"\"\n","import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\"\n","\n","!pip install timm\n","!pip install torchattacks"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32837,"status":"ok","timestamp":1711139349969,"user":{"displayName":"Tanishq Trivedi","userId":"08401598246083797041"},"user_tz":-330},"id":"Ty7gQHyRA-jy","outputId":"c121aa8c-b562-4012-c7e9-7a9b71f6a64c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["\"\"\"connect to google drive to store and retrieve data\"\"\"\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"TA7_SNg7zjui"},"source":["**Dataset Loader**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AnK4QeZqcafS"},"outputs":[],"source":["from torch.utils.data import Dataset\n","import torch\n","import torchaudio\n","import torchvision\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","\n","class FSCDataset(Dataset):\n","    def __init__(self, annotations_file, audio_dir, device, num_samples=80000, sr=16000):\n","        self.device = device\n","        self.annotations = pd.read_csv(annotations_file)\n","        self.audio_dir = audio_dir\n","        self.num_samples = num_samples\n","        self.sample_rate = sr\n","        self.transform = torchvision.transforms.Compose([\n","            # convert signal to mel spectrogam\n","            torchaudio.transforms.MelSpectrogram(sample_rate=self.sample_rate, n_fft=2048, hop_length=512).to(self.device),\n","            # convert to log scale\n","            torchaudio.transforms.AmplitudeToDB().to(self.device),\n","            # resize to 224x224\n","            torchvision.transforms.Resize((224, 224), antialias=True).to(self.device),\n","            # change to [0, 1] range using min max scaling\n","            torchvision.transforms.Lambda(lambda x: (x - x.min()) / (x.max() - x.min()))\n","        ])\n","\n","        self.data = {}\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def __getitem__(self, index):\n","        audio_sample_path = self._get_audio_sample_path(index)\n","        label = self._get_audio_sample_label(index)\n","        signal, sr = torchaudio.load(audio_sample_path)\n","        signal = signal.to(self.device)\n","\n","        # make number of channels = 1\n","        if signal.shape[0] > 1:\n","            signal = torch.mean(signal, dim=0, keepdim=True)\n","\n","        # resampling to make the sample rate as sample_rate\n","        resample_transform = torchaudio.transforms.Resample(sr, self.sample_rate).to(self.device)\n","        signal = resample_transform(signal)\n","\n","        # cut if more samples than sample_rate * duration\n","        if (signal.shape[1] > self.num_samples):\n","            signal = signal[:, :self.num_samples]\n","\n","        # right pad 0s if less than num_samples\n","        if (signal.shape[1] < self.num_samples):\n","            num_missing = self.num_samples - signal.shape[1]\n","            last_dim_padding = (0, num_missing)\n","            signal = torch.nn.functional.pad(signal, last_dim_padding)\n","\n","        mel_spectrogram = self.transform(signal)\n","\n","        return mel_spectrogram, label\n","\n","\n","    def _get_audio_sample_path(self, index):\n","        filename = self.annotations.iloc[index, 1]\n","        path = os.path.join(self.audio_dir, filename)\n","        return path\n","\n","    def _get_audio_sample_label(self, index):\n","        return self.annotations.iloc[index, 2] - 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":730,"status":"ok","timestamp":1709538119562,"user":{"displayName":"hvg nmjk","userId":"04519037497384016652"},"user_tz":-330},"id":"YWPidpBDdBKM","outputId":"9461c9c2-ca72-4385-b9d2-4c5093145071"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cpu\n","Total number of samples present in dataset: 2025\n"]}],"source":["ANNOTATIONS_FILE = \"/content/drive/MyDrive/data/FSC22dataset/Metadata/MetadataV1.0FSC22.csv\"\n","AUDIO_DIR = \"/content/drive/MyDrive/data/FSC22dataset/AudioWiseV1.0\"\n","SAMPLE_RATE=16000\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f'Using device: {device}')\n","\n","fsc = FSCDataset(ANNOTATIONS_FILE, AUDIO_DIR, device)\n","print(f\"Total number of samples present in dataset: {len(fsc)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":689308,"status":"ok","timestamp":1709538832182,"user":{"displayName":"hvg nmjk","userId":"04519037497384016652"},"user_tz":-330},"id":"wHiRaIBKBy-y","outputId":"76296c77-0eb6-401a-f0b7-5b28e8dd742c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset saved to /content/drive/MyDrive/data/AdvData/FSC22.h5\n"]}],"source":["import h5py\n","\n","h5_file_path = '/content/drive/MyDrive/data/AdvData/FSC22.h5'\n","with h5py.File(h5_file_path, 'w') as hf:\n","    for i in range(len(fsc)):\n","        data, label = fsc[i]\n","\n","        # Create datasets within the HDF5 file\n","        grp = hf.create_group(f'sample_{i}')\n","        grp.create_dataset('data', data=data.cpu().numpy())\n","        grp.create_dataset('label', data=label)\n","\n","print(\"Dataset saved to\", h5_file_path)"]},{"cell_type":"markdown","metadata":{"id":"d1sTilKkYtRP"},"source":["# Directly load data from h5 file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"95rqKa_hVuBG"},"outputs":[],"source":["import h5py\n","import torch\n","from torch.utils.data import TensorDataset\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","data_list = []\n","label_list = []\n","\n","# Open the HDF5 file\n","h5_file_path = '/content/drive/MyDrive/data/AdvData/FSC22.h5'\n","with h5py.File(h5_file_path, 'r') as hf:\n","    # Iterate over the samples in the HDF5 file\n","    for sample_name in hf.keys():\n","        data = torch.tensor(hf[sample_name]['data'][:])\n","        label = hf[sample_name]['label'][()]\n","\n","        # Append data and label to lists\n","        data_list.append(data)\n","        label_list.append(label)\n","\n","fsc = TensorDataset(torch.stack(data_list), torch.tensor(label_list))"]},{"cell_type":"markdown","metadata":{"id":"H0gduSpYWcuc"},"source":["**Function to train the model and calculate metrics**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KepPiK1ihNaH"},"outputs":[],"source":["from torch.optim.lr_scheduler import StepLR\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.utils.data import random_split\n","import torch.nn.functional as F\n","from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, accuracy_score\n","from sklearn.manifold import TSNE\n","import seaborn as sns\n","\n","# function to train the model\n","def train_model(model, dataset, learning_rate=2e-4, num_epochs=10, batch_size=128, stepSize=10, gamma=0.1, validation_split=0.2, patience=3):\n","    model = model.to(device)\n","\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    loss_fn = nn.CrossEntropyLoss()\n","    scheduler = StepLR(optimizer, step_size=stepSize, gamma=gamma)\n","    # scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n","\n","    # Split dataset into training and validation sets\n","    num_samples = len(dataset)\n","    num_validation_samples = int(validation_split * num_samples)\n","    num_training_samples = num_samples - num_validation_samples\n","    training_dataset, validation_dataset = random_split(dataset, [num_training_samples, num_validation_samples])\n","\n","    train_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n","    valid_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n","\n","    best_valid_loss = float('inf')\n","    patience_counter = 0\n","    for epoch in range(num_epochs):\n","        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n","        model.train()\n","        for batch_input, batch_target in train_loader:\n","            batch_input, batch_target = batch_input.to(device), batch_target.to(device)\n","            optimizer.zero_grad()\n","\n","            predictions = model(batch_input)\n","\n","            loss = loss_fn(predictions, batch_target)\n","            loss.backward()\n","\n","            optimizer.step()\n","\n","        print(f\"  Training Loss: {loss.item()}\")\n","\n","        # Validation phase\n","        model.eval()\n","        with torch.no_grad():\n","            valid_loss = 0\n","            correct = 0\n","            total = 0\n","            for batch_input, batch_target in valid_loader:\n","                batch_input, batch_target = batch_input.to(device), batch_target.to(device)\n","                predictions = model(batch_input)\n","                _, predicted = torch.max(predictions, 1)\n","                total += batch_target.size(0)\n","                correct += (predicted == batch_target).sum().item()\n","                valid_loss += loss_fn(predictions, batch_target).item()\n","\n","            accuracy = correct / total\n","            valid_loss /= len(valid_loader)\n","            print(f\"  Validation Loss: {valid_loss}, Accuracy: {accuracy * 100:.2f}%\")\n","\n","            # Check for early stopping\n","            if valid_loss < best_valid_loss:\n","                best_valid_loss = valid_loss\n","                patience_counter = 0\n","            else:\n","                patience_counter += 1\n","                if patience_counter >= patience:\n","                    print(f\"Early stopping after {patience} epochs of no improvement.\")\n","                    return\n","\n","        scheduler.step()\n","\n","    print(\"Training finished.\")\n","\n","# function to calculate metrics\n","def calculate_metrics(model, dataset):\n","    data_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n","    model = model.to(device)\n","    model.eval()\n","    all_predictions = []\n","    all_targets = []\n","\n","    with torch.no_grad():\n","        for batch_input, batch_target in data_loader:\n","            batch_input, batch_target = batch_input.to(device), batch_target.to(device)\n","            predictions = model(batch_input)\n","            all_predictions.append(predictions.argmax(dim=1))\n","            all_targets.append(batch_target)\n","\n","    all_predictions = torch.cat(all_predictions).cpu().numpy()\n","    all_targets = torch.cat(all_targets).cpu().numpy()\n","\n","    accuracy = accuracy_score(all_targets, all_predictions)\n","    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n","\n","    # precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_predictions, average='weighted')\n","    # print(f\"Precision: {precision:.4f}\")\n","    # print(f\"Recall: {recall:.4f}\")\n","    # print(f\"F1 Score: {f1:.4f}\")\n","\n","    # cm = confusion_matrix(all_targets, all_predictions)\n","    # # Plot the confusion matrix using Seaborn\n","    # sns.heatmap(cm, annot=True)\n","    # plt.title(\"Confusion Matrix\")\n","    # plt.xlabel(\"Predicted Label\")\n","    # plt.ylabel(\"True Label\")\n","    # plt.show()"]},{"cell_type":"code","source":["import torchattacks\n","import h5py\n","import time\n","\n","def generate_adversarial(dataset, model, model_name):\n","    data_loader = DataLoader(dataset, batch_size=32)\n","    model = model.to(device)\n","\n","    attack_dict = {}\n","    attack_dict['fgsm'] = torchattacks.FGSM(model, eps=8/255)\n","    attack_dict['fgsm'].set_mode_targeted_by_label()\n","\n","    attack_dict['bim'] = torchattacks.BIM(model, eps=8/255, alpha=2/255, steps=4)\n","    attack_dict['bim'].set_mode_targeted_by_label()\n","\n","    attack_dict['pgd'] = torchattacks.PGD(model, eps=8/255, alpha=1/255, steps=4, random_start=True)\n","    attack_dict['pgd'].set_mode_targeted_by_label()\n","\n","    attack_dict['cw'] = torchattacks.CW(model, c=1, kappa=0, steps=20, lr=0.01)\n","    attack_dict['cw'].set_mode_targeted_by_label()\n","\n","    for name, attk in attack_dict.items():\n","        st = time.time()\n","        i = 0\n","        current_batch = 0\n","        h5_file_path = f'/content/drive/MyDrive/data/Target/FSC22/{model_name}/{name}.h5'\n","        with h5py.File(h5_file_path, 'a') as hf:\n","            print(f\"started {name}\")\n","            for batch_input, batch_target in data_loader:\n","\n","                # generate adv image for image\n","                batch_input, batch_target = batch_input.to(device), batch_target.to(device)\n","                new_labels = torch.full((batch_target.size()), 19).to(device)\n","                # clapping 19\n","\n","                adv_images = attk(batch_input, new_labels)\n","\n","                # write in h5 file\n","                for j in range(batch_input.shape[0]):\n","                    grp_name = f'sample_{i}'\n","                    if grp_name in hf:\n","                        del hf[grp_name]  # Delete existing group\n","                    grp = hf.create_group(f'sample_{i}')\n","                    grp.create_dataset('data', data=adv_images[j].cpu().numpy())\n","                    grp.create_dataset('label', data=batch_target[j].cpu())\n","                    i += 1\n","                if (current_batch % 100 == 0):\n","                    print(f\"{current_batch} - \", end=\"\")\n","                current_batch += 1\n","            print(\"\\n\")\n","\n","        end = time.time()\n","        print(f'{name} adv dataset for {model_name}')\n","\"\"\"\n","runs the given model on all adv dataset of `adv_dir` directory\n","\"\"\"\n","def calculate_accuracy_for_adv_data(model, model_name, adv_dir):\n","    attk_list = ['fgsm', 'bim', 'pgd', 'cw']\n","\n","    for attk in attk_list:\n","        h5_file_path = '/content/drive/MyDrive/data/Target/FSC22/{adv_dir}/{attk}.h5'\n","        data_list = []\n","        label_list = []\n","\n","        with h5py.File(h5_file_path, 'r') as hf:\n","            # Iterate over the samples in the HDF5 file\n","            for sample_name in hf.keys():\n","                data = torch.tensor(hf[sample_name]['data'][:])\n","                label = hf[sample_name]['label'][()]\n","\n","                # Append data and label to lists\n","                data_list.append(data)\n","                label_list.append(label)\n","\n","        dataset_class = SpectrogramDataset(data_list, label_list)\n","        print(f'Stats for {model_name} on {adv_dir}/{attk} dataset')\n","        calculate_metrics(model, dataset_class)\n","\n","def for_all(model, model_name):\n","    adv_dirs = ['resnet18', 'resnet50', 'vit_base', 'vit_large', 'mixer']\n","    for adv in adv_dirs:\n","        calculate_accuracy_for_adv_data(model, model_name, adv)"],"metadata":{"id":"_wFSW0C_5fxJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jG88hNBskc0_"},"source":["# ResNet 18"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FhFNcRq4zgON"},"outputs":[],"source":["import timm\n","\n","resnet18 = timm.create_model('resnet18.a1_in1k', pretrained=True)\n","resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","resnet18.fc = nn.Linear(in_features=512, out_features=27, bias=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57215,"status":"ok","timestamp":1709655940260,"user":{"displayName":"Tanishq Trivedi","userId":"12574579820699221693"},"user_tz":-330},"id":"z2Lt3pa4kb7z","outputId":"043bcaa5-08f9-4d03-eedf-4a5d05f46d2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/12\n","  Training Loss: 2.710721969604492\n","  Validation Loss: 3.2435966559818814, Accuracy: 6.67%\n","Epoch 2/12\n","  Training Loss: 2.0344345569610596\n","  Validation Loss: 3.0930284091404507, Accuracy: 9.38%\n","Epoch 3/12\n","  Training Loss: 1.4377520084381104\n","  Validation Loss: 2.5995363167354038, Accuracy: 19.26%\n","Epoch 4/12\n","  Training Loss: 1.374700665473938\n","  Validation Loss: 2.0250676529748097, Accuracy: 40.00%\n","Epoch 5/12\n","  Training Loss: 0.4959043860435486\n","  Validation Loss: 2.191277861595154, Accuracy: 33.58%\n","Epoch 6/12\n","  Training Loss: 0.7159674763679504\n","  Validation Loss: 1.7947085074016027, Accuracy: 49.14%\n","Epoch 7/12\n","  Training Loss: 0.39392462372779846\n","  Validation Loss: 2.6157002108437672, Accuracy: 29.14%\n","Epoch 8/12\n","  Training Loss: 0.36386561393737793\n","  Validation Loss: 1.3515149354934692, Accuracy: 59.01%\n","Epoch 9/12\n","  Training Loss: 0.35319042205810547\n","  Validation Loss: 1.359156506402152, Accuracy: 59.75%\n","Epoch 10/12\n","  Training Loss: 0.45977360010147095\n","  Validation Loss: 1.3678297996520996, Accuracy: 61.73%\n","Epoch 11/12\n","  Training Loss: 0.23950500786304474\n","  Validation Loss: 1.0324073263577052, Accuracy: 71.36%\n","Epoch 12/12\n","  Training Loss: 0.27419525384902954\n","  Validation Loss: 1.0185749701091222, Accuracy: 72.59%\n","Training finished.\n"]}],"source":["torch.cuda.empty_cache()\n","train_model(resnet18, fsc, learning_rate=1e-3, num_epochs=12, batch_size=64)\n","\n","torch.save(resnet18.state_dict(), '/content/drive/MyDrive/data/Models/FSC22/resnet18.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ZYvftpOCXuB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711139656310,"user_tz":-330,"elapsed":89463,"user":{"displayName":"Tanishq Trivedi","userId":"08401598246083797041"}},"outputId":"9dbb75ec-6a5d-4417-b1b6-6ed24912f513"},"outputs":[{"output_type":"stream","name":"stdout","text":["Attack mode is changed to 'targeted(label)'.\n","Attack mode is changed to 'targeted(label)'.\n","Attack mode is changed to 'targeted(label)'.\n","Attack mode is changed to 'targeted(label)'.\n","started fgsm\n","0 - \n","\n","fgsm adv dataset for resnet18\n","started bim\n","0 - \n","\n","bim adv dataset for resnet18\n","started pgd\n","0 - \n","\n","pgd adv dataset for resnet18\n","started cw\n","0 - \n","\n","cw adv dataset for resnet18\n"]}],"source":["torch.cuda.empty_cache()\n","checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/resnet18.pth')\n","resnet18.load_state_dict(checkpoint)\n","\n","generate_adversarial(fsc, resnet18, 'resnet18')"]},{"cell_type":"code","source":["import timm\n","\n","def ret_pred(model, dataset):\n","    data_loader = DataLoader(dataset, batch_size=128)\n","    model = model.to(device)\n","    model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for batch_input, batch_target in data_loader:\n","            batch_input = batch_input.to(device)\n","            predictions = model(batch_input)\n","            all_predictions.append(predictions.argmax(dim=1))\n","\n","    all_predictions = torch.cat(all_predictions)\n","    return all_predictions\n","\n","def cal_ratio():\n","    attk_list = ['fgsm', 'bim', 'pgd', 'cw']\n","    adv_dir = 'resnet18'\n","\n","\n","    for attk in attk_list:\n","        h5_file_path = f'/content/drive/MyDrive/data/Target/FSC22/{adv_dir}/{attk}.h5'\n","        data_list = []\n","        label_list = []\n","\n","        with h5py.File(h5_file_path, 'r') as hf:\n","            # Iterate over the samples in the HDF5 file\n","            for sample_name in hf.keys():\n","                data = torch.tensor(hf[sample_name]['data'][:])\n","                label = hf[sample_name]['label'][()]\n","\n","                # Append data and label to lists\n","                data_list.append(data)\n","                label_list.append(label)\n","\n","        dataset_class = TensorDataset(torch.stack(data_list), torch.tensor(label_list))\n","        label_list = torch.tensor(label_list)\n","\n","        resnet18 = timm.create_model('resnet18.a1_in1k', pretrained=True)\n","        resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        resnet18.fc = nn.Linear(in_features=512, out_features=27, bias=True)\n","        torch.cuda.empty_cache()\n","        checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/resnet18.pth')\n","        resnet18.load_state_dict(checkpoint)\n","        r18 = ret_pred(resnet18, dataset_class)\n","\n","        unfooled = 0\n","        diff = 0\n","        same = 0\n","        for i in range(2025):\n","            if (r18[i] == label_list[i]):\n","                unfooled += 1\n","            else:\n","                same += 1\n","\n","        print (unfooled/2025, same/2025, diff/2025)\n","\n","        print(f'Ratio for {adv_dir}/{attk} dataset')\n","\n","        resnet50 = timm.create_model('resnet50.a1_in1k', pretrained=True)\n","        resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        resnet50.fc = nn.Linear(in_features=2048, out_features=27, bias=True)\n","        torch.cuda.empty_cache()\n","        checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/resnet50.pth')\n","        resnet50.load_state_dict(checkpoint)\n","        r50 = ret_pred(resnet50, dataset_class)\n","\n","        unfooled = 0\n","        diff = 0\n","        same = 0\n","        for i in range(2025):\n","            if (r50[i] == label_list[i]):\n","                unfooled += 1\n","            elif (r50[i] == r18[i]):\n","                same += 1\n","            else:\n","                diff += 1\n","\n","        print (unfooled/2025, same/2025, diff/2025)\n","\n","        vit_base = timm.create_model('vit_base_patch16_224.augreg2_in21k_ft_in1k', pretrained=True)\n","        vit_base.patch_embed.proj = nn.Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16))\n","        vit_base.head = nn.Linear(in_features=768, out_features=27, bias=True)\n","        torch.cuda.empty_cache()\n","        checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/vit_base.pth')\n","        vit_base.load_state_dict(checkpoint)\n","        vb = ret_pred(vit_base, dataset_class)\n","\n","        unfooled = 0\n","        diff = 0\n","        same = 0\n","        for i in range(2025):\n","            if (vb[i] == label_list[i]):\n","                unfooled += 1\n","            elif (vb[i] == r18[i]):\n","                same += 1\n","            else:\n","                diff += 1\n","\n","        print (unfooled/2025, same/2025, diff/2025)\n","\n","        mixer = timm.create_model('mixer_b16_224.goog_in21k_ft_in1k', pretrained=True)\n","        mixer.stem.proj = nn.Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16))\n","        mixer.head = nn.Linear(in_features=768, out_features=27, bias=True)\n","        torch.cuda.empty_cache()\n","        checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/mixer.pth')\n","        mixer.load_state_dict(checkpoint)\n","        m = ret_pred(mixer, dataset_class)\n","\n","        unfooled = 0\n","        diff = 0\n","        same = 0\n","        for i in range(2025):\n","            if (m[i] == label_list[i]):\n","                unfooled += 1\n","            elif (m[i] == r18[i]):\n","                same += 1\n","            else:\n","                diff += 1\n","\n","        print (unfooled/2025, same/2025, diff/2025)\n","\n","        del dataset_class\n","        del data_list\n","        del label_list"],"metadata":{"id":"pJtl2FC5Xx4v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cal_ratio()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHU3c0rIlzGQ","executionInfo":{"status":"ok","timestamp":1711143674716,"user_tz":-330,"elapsed":845550,"user":{"displayName":"Tanishq Trivedi","userId":"08401598246083797041"}},"outputId":"04ca33f1-6d70-4a3a-9f2c-55770b786342"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.22666666666666666 0.7733333333333333 0.0\n","Ratio for resnet18/fgsm dataset\n","0.7318518518518519 0.06814814814814815 0.2\n","0.6834567901234568 0.03259259259259259 0.2839506172839506\n","0.9279012345679012 0.006419753086419753 0.06567901234567901\n","0.057777777777777775 0.9422222222222222 0.0\n","Ratio for resnet18/bim dataset\n","0.9293827160493827 0.0009876543209876543 0.06962962962962962\n","0.6893827160493827 0.008888888888888889 0.3017283950617284\n","0.9288888888888889 0.0014814814814814814 0.06962962962962962\n","0.08049382716049383 0.9195061728395062 0.0\n","Ratio for resnet18/pgd dataset\n","0.9160493827160494 0.0004938271604938272 0.08345679012345679\n","0.6869135802469136 0.008888888888888889 0.30419753086419754\n","0.928395061728395 0.0014814814814814814 0.07012345679012345\n","0.7619753086419753 0.2380246913580247 0.0\n","Ratio for resnet18/cw dataset\n","0.9501234567901234 0.0049382716049382715 0.044938271604938275\n","0.688395061728395 0.0049382716049382715 0.30666666666666664\n","0.928395061728395 0.0034567901234567903 0.06814814814814815\n"]}]},{"cell_type":"markdown","metadata":{"id":"xO6L9C3cCf7n"},"source":["# Resnet 50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GiqiuKW2CiB9","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["1d39bbbfb9034d039a9bc7d2a138cd07","058d227039b54646a5fdf4f8369c30a2","4f233774dce540ef944ebdcff00f7830","0fadcf391ac9466284da6cc965848e5f","6e30245847b647b0bb2c2beaa2eabb56","8790c700cb67411db595461bf12f0dd3","4e7f869b68634a708a98ca4a936c8ba5","29b9cdf4a5544165a77899525be339a4","c409612d371442c99f20a02e2bcea375","baf92b9a1952411c85054c1e75294ff0","700cf46122af4e0e802ae77fd6836a0f"]},"executionInfo":{"status":"ok","timestamp":1711139668650,"user_tz":-330,"elapsed":1759,"user":{"displayName":"Tanishq Trivedi","userId":"08401598246083797041"}},"outputId":"cbeb2019-ae26-4b61-e820-a02786ad2204"},"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d39bbbfb9034d039a9bc7d2a138cd07"}},"metadata":{}}],"source":["import timm\n","\n","resnet50 = timm.create_model('resnet50.a1_in1k', pretrained=True)\n","resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","resnet50.fc = nn.Linear(in_features=2048, out_features=27, bias=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJEgGoFVClFO","executionInfo":{"status":"ok","timestamp":1709655644070,"user_tz":-330,"elapsed":194216,"user":{"displayName":"Tanishq Trivedi","userId":"12574579820699221693"}},"outputId":"8adc2a0d-c0ff-49a0-d946-9c368b07b309"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/12\n","  Training Loss: 2.4980111122131348\n","  Validation Loss: 3.47109545980181, Accuracy: 2.72%\n","Epoch 2/12\n","  Training Loss: 1.5741358995437622\n","  Validation Loss: 3.3762620857783725, Accuracy: 9.63%\n","Epoch 3/12\n","  Training Loss: 1.252087950706482\n","  Validation Loss: 2.4790454592023576, Accuracy: 27.90%\n","Epoch 4/12\n","  Training Loss: 0.8580464124679565\n","  Validation Loss: 1.9976906776428223, Accuracy: 39.51%\n","Epoch 5/12\n","  Training Loss: 0.6934912800788879\n","  Validation Loss: 1.8577135971614294, Accuracy: 50.12%\n","Epoch 6/12\n","  Training Loss: 1.0673478841781616\n","  Validation Loss: 1.3955492292131697, Accuracy: 54.07%\n","Epoch 7/12\n","  Training Loss: 0.7631818056106567\n","  Validation Loss: 1.303287148475647, Accuracy: 63.21%\n","Epoch 8/12\n","  Training Loss: 0.27572065591812134\n","  Validation Loss: 1.6422770534242903, Accuracy: 56.30%\n","Epoch 9/12\n","  Training Loss: 0.16625110805034637\n","  Validation Loss: 0.9815296104976109, Accuracy: 73.83%\n","Epoch 10/12\n","  Training Loss: 0.394150048494339\n","  Validation Loss: 0.9391197562217712, Accuracy: 74.81%\n","Epoch 11/12\n","  Training Loss: 0.0527028851211071\n","  Validation Loss: 0.9227679967880249, Accuracy: 75.56%\n","Epoch 12/12\n","  Training Loss: 0.14442071318626404\n","  Validation Loss: 0.9376907093184335, Accuracy: 75.56%\n","Training finished.\n"]}],"source":["torch.cuda.empty_cache()\n","train_model(resnet50, fsc, learning_rate=1e-3, num_epochs=12, batch_size=64, stepSize=8)\n","\n","torch.save(resnet50.state_dict(), '/content/drive/MyDrive/data/Models/FSC22/resnet50.pth')"]},{"cell_type":"code","source":["import timm\n","\n","def ret_pred(model, dataset):\n","    data_loader = DataLoader(dataset, batch_size=128)\n","    model = model.to(device)\n","    model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for batch_input, batch_target in data_loader:\n","            batch_input = batch_input.to(device)\n","            predictions = model(batch_input)\n","            all_predictions.append(predictions.argmax(dim=1))\n","\n","    all_predictions = torch.cat(all_predictions)\n","    return all_predictions\n","\n","def cal_ratio():\n","    attk_list = ['fgsm', 'bim', 'pgd', 'cw']\n","    adv_dir = 'resnet50'\n","\n","\n","    for attk in attk_list:\n","        h5_file_path = f'/content/drive/MyDrive/data/Target/FSC22/{adv_dir}/{attk}.h5'\n","        data_list = []\n","        label_list = []\n","\n","        with h5py.File(h5_file_path, 'r') as hf:\n","            # Iterate over the samples in the HDF5 file\n","            for sample_name in hf.keys():\n","                data = torch.tensor(hf[sample_name]['data'][:])\n","                label = hf[sample_name]['label'][()]\n","\n","                # Append data and label to lists\n","                data_list.append(data)\n","                label_list.append(label)\n","\n","        dataset_class = TensorDataset(torch.stack(data_list), torch.tensor(label_list))\n","        label_list = torch.tensor(label_list)\n","\n","        resnet50 = timm.create_model('resnet50.a1_in1k', pretrained=True)\n","        resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        resnet50.fc = nn.Linear(in_features=2048, out_features=27, bias=True)\n","        torch.cuda.empty_cache()\n","        checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/resnet50.pth')\n","        resnet50.load_state_dict(checkpoint)\n","        r18 = ret_pred(resnet50, dataset_class)\n","        unfooled = 0\n","        diff = 0\n","        same = 0\n","        for i in range(2025):\n","            if (r18[i] == label_list[i]):\n","                unfooled += 1\n","            else:\n","                same += 1\n","\n","        print (unfooled/2025, same/2025, diff/2025)\n","\n","        print(f'Ratio for {adv_dir}/{attk} dataset')\n","\n","        resnet18 = timm.create_model('resnet18.a1_in1k', pretrained=True)\n","        resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        resnet18.fc = nn.Linear(in_features=512, out_features=27, bias=True)\n","        torch.cuda.empty_cache()\n","        checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/resnet18.pth')\n","        resnet18.load_state_dict(checkpoint)\n","        r50 = ret_pred(resnet18, dataset_class)\n","\n","        unfooled = 0\n","        diff = 0\n","        same = 0\n","        for i in range(2025):\n","            if (r50[i] == label_list[i]):\n","                unfooled += 1\n","            elif (r50[i] == r18[i]):\n","                same += 1\n","            else:\n","                diff += 1\n","\n","        print (unfooled/2025, same/2025, diff/2025)\n","\n","        vit_base = timm.create_model('vit_base_patch16_224.augreg2_in21k_ft_in1k', pretrained=True)\n","        vit_base.patch_embed.proj = nn.Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16))\n","        vit_base.head = nn.Linear(in_features=768, out_features=27, bias=True)\n","        torch.cuda.empty_cache()\n","        checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/vit_base.pth')\n","        vit_base.load_state_dict(checkpoint)\n","        vb = ret_pred(vit_base, dataset_class)\n","\n","        unfooled = 0\n","        diff = 0\n","        same = 0\n","        for i in range(2025):\n","            if (vb[i] == label_list[i]):\n","                unfooled += 1\n","            elif (vb[i] == r18[i]):\n","                same += 1\n","            else:\n","                diff += 1\n","\n","        print (unfooled/2025, same/2025, diff/2025)\n","\n","        mixer = timm.create_model('mixer_b16_224.goog_in21k_ft_in1k', pretrained=True)\n","        mixer.stem.proj = nn.Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16))\n","        mixer.head = nn.Linear(in_features=768, out_features=27, bias=True)\n","        torch.cuda.empty_cache()\n","        checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/mixer.pth')\n","        mixer.load_state_dict(checkpoint)\n","        m = ret_pred(mixer, dataset_class)\n","\n","        unfooled = 0\n","        diff = 0\n","        same = 0\n","        for i in range(2025):\n","            if (m[i] == label_list[i]):\n","                unfooled += 1\n","            elif (m[i] == r18[i]):\n","                same += 1\n","            else:\n","                diff += 1\n","\n","        print (unfooled/2025, same/2025, diff/2025)\n","\n","        del dataset_class\n","        del data_list\n","        del label_list\n","\n","cal_ratio()"],"metadata":{"id":"adB--w0vX6a_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711144693182,"user_tz":-330,"elapsed":1005468,"user":{"displayName":"Tanishq Trivedi","userId":"08401598246083797041"}},"outputId":"fb7228d0-97e7-4f8a-eb82-12e0b33bf940"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.3530864197530864 0.6469135802469136 0.0\n","Ratio for resnet50/fgsm dataset\n","0.6266666666666667 0.10765432098765432 0.26567901234567903\n","0.6879012345679012 0.037037037037037035 0.2750617283950617\n","0.9264197530864198 0.011358024691358024 0.06222222222222222\n","0.10469135802469136 0.8953086419753087 0.0\n","Ratio for resnet50/bim dataset\n","0.9101234567901234 0.003950617283950617 0.08592592592592592\n","0.6859259259259259 0.013333333333333334 0.30074074074074075\n","0.9274074074074075 0.0019753086419753087 0.07061728395061728\n","0.1145679012345679 0.885432098765432 0.0\n","Ratio for resnet50/pgd dataset\n","0.8780246913580247 0.0049382716049382715 0.11703703703703704\n","0.6859259259259259 0.011851851851851851 0.3022222222222222\n","0.9279012345679012 0.0049382716049382715 0.0671604938271605\n","0.8409876543209877 0.15901234567901235 0.0\n","Ratio for resnet50/cw dataset\n","0.9432098765432099 0.005925925925925926 0.0508641975308642\n","0.6879012345679012 0.010864197530864197 0.3012345679012346\n","0.9279012345679012 0.0024691358024691358 0.06962962962962962\n"]}]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/resnet50.pth')\n","resnet50.load_state_dict(checkpoint)\n","\n","generate_adversarial(fsc, resnet50, 'resnet50')"],"metadata":{"id":"I2IDtOraM0T_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711139903759,"user_tz":-330,"elapsed":224321,"user":{"displayName":"Tanishq Trivedi","userId":"08401598246083797041"}},"outputId":"206daf21-22a8-48ed-a72a-917bf215920a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attack mode is changed to 'targeted(label)'.\n","Attack mode is changed to 'targeted(label)'.\n","Attack mode is changed to 'targeted(label)'.\n","Attack mode is changed to 'targeted(label)'.\n","started fgsm\n","0 - \n","\n","fgsm adv dataset for resnet50\n","started bim\n","0 - \n","\n","bim adv dataset for resnet50\n","started pgd\n","0 - \n","\n","pgd adv dataset for resnet50\n","started cw\n","0 - \n","\n","cw adv dataset for resnet50\n"]}]},{"cell_type":"markdown","metadata":{"id":"tx5ao7f-p96k"},"source":["# VIT Base"]},{"cell_type":"code","source":["import timm\n","\n","vit_base = timm.create_model('vit_base_patch16_224.augreg2_in21k_ft_in1k', pretrained=True)\n","vit_base.patch_embed.proj = nn.Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16))\n","vit_base.head = nn.Linear(in_features=768, out_features=27, bias=True)"],"metadata":{"id":"-RPfKOcv22-y","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["68ba781c817c49fbacff636cf38f1d9e","31fca44e8af04b48aad45e3620865789","c8343049a1104017a656f74313ad61ae","20ed308269ae4f769b1c00ad99fa764f","6274a982039a4732bd75eb9567620095","1da4a11647e94dd49bb3a9d7b74fc818","abf6397427da48d19a7b85ce98f91dcb","7a1bc31ab5094d0b9882788d793066f3","73c298075759441f9a086265468e7fa0","8880251664a846339c24c744b795eb2b","4cde270a8a124b80872d38bb0640b254"]},"executionInfo":{"status":"ok","timestamp":1711141064914,"user_tz":-330,"elapsed":3635,"user":{"displayName":"Tanishq Trivedi","userId":"08401598246083797041"}},"outputId":"eed4e438-33da-463f-9964-27aee91cbfe7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68ba781c817c49fbacff636cf38f1d9e"}},"metadata":{}}]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","train_model(vit_base, fsc, learning_rate=1e-4, num_epochs=12, batch_size=32, patience=3)\n","\n","torch.save(vit_base.state_dict(), '/content/drive/MyDrive/data/Models/FSC22/vit_base.pth')"],"metadata":{"id":"Ft7rSo3i28-7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709663410223,"user_tz":-330,"elapsed":684847,"user":{"displayName":"Tanishq Trivedi","userId":"12574579820699221693"}},"outputId":"0da9f606-7de7-4097-a68d-648e24cac1bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/12\n","  Training Loss: 3.4033825397491455\n","  Validation Loss: 3.3511867706592264, Accuracy: 3.70%\n","Epoch 2/12\n","  Training Loss: 3.2229294776916504\n","  Validation Loss: 3.2032161309168887, Accuracy: 6.91%\n","Epoch 3/12\n","  Training Loss: 2.8648111820220947\n","  Validation Loss: 2.9743086924919715, Accuracy: 11.36%\n","Epoch 4/12\n","  Training Loss: 2.601235866546631\n","  Validation Loss: 2.750975113648635, Accuracy: 18.52%\n","Epoch 5/12\n","  Training Loss: 2.6651289463043213\n","  Validation Loss: 2.707651064946101, Accuracy: 20.00%\n","Epoch 6/12\n","  Training Loss: 2.401378631591797\n","  Validation Loss: 2.3539011845221887, Accuracy: 29.38%\n","Epoch 7/12\n","  Training Loss: 2.397432804107666\n","  Validation Loss: 2.1694906766598043, Accuracy: 34.81%\n","Epoch 8/12\n","  Training Loss: 1.7917802333831787\n","  Validation Loss: 2.1182315349578857, Accuracy: 34.81%\n","Epoch 9/12\n","  Training Loss: 2.3528709411621094\n","  Validation Loss: 2.0192835881159854, Accuracy: 38.02%\n","Epoch 10/12\n","  Training Loss: 1.8000625371932983\n","  Validation Loss: 2.0445750676668606, Accuracy: 42.47%\n","Epoch 11/12\n","  Training Loss: 1.1256392002105713\n","  Validation Loss: 1.7291795565531805, Accuracy: 50.86%\n","Epoch 12/12\n","  Training Loss: 0.7002379894256592\n","  Validation Loss: 1.8079653978347778, Accuracy: 49.14%\n","Training finished.\n"]}]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/vit_base.pth')\n","vit_base.load_state_dict(checkpoint)\n","\n","generate_adversarial(fsc, vit_base, 'vit_base')"],"metadata":{"id":"882KitpZnff1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711142609347,"user_tz":-330,"elapsed":1462335,"user":{"displayName":"Tanishq Trivedi","userId":"08401598246083797041"}},"outputId":"0bd47370-1e6f-4f89-c471-8bb1facce52e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attack mode is changed to 'targeted(label)'.\n","Attack mode is changed to 'targeted(label)'.\n","Attack mode is changed to 'targeted(label)'.\n","Attack mode is changed to 'targeted(label)'.\n","started fgsm\n","0 - \n","\n","fgsm adv dataset for vit_base\n","started bim\n","0 - \n","\n","bim adv dataset for vit_base\n","started pgd\n","0 - \n","\n","pgd adv dataset for vit_base\n","started cw\n","0 - \n","\n","cw adv dataset for vit_base\n"]}]},{"cell_type":"markdown","metadata":{"id":"NZTz4XXhp_wG"},"source":["# VIT Large"]},{"cell_type":"code","source":["import timm\n","\n","vit_large = timm.create_model('vit_large_patch16_224.augreg_in21k_ft_in1k', pretrained=True)\n","vit_large.patch_embed.proj = nn.Conv2d(1, 1024, kernel_size=(16, 16), stride=(16, 16))\n","vit_large.head = nn.Linear(in_features=1024, out_features=27, bias=True)"],"metadata":{"id":"uoMemOi73Cax","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["09791e34afc84f7f94439c45c8c682f2","ee0d811199d24ce1a0aac7b0efaefad5","763c7f70ad32440f89e040379189ad8a","c6de2825b71d4c3c8474876207b744c4","09d1fa16c2a2461ebe69f851a4c8a282","23f463bdaa8443dcb2a6bb95d0e9da57","9ff5442987de43688255a262ba3705f2","1682d4d05ab64c5a818db3c033474048","3bb39db179a4402499f98ae8a87f71a4","652b9c1e70e84d30a7413ca0980e89ce","a118248bc08e46cdaa62f3e4492eba58"]},"executionInfo":{"status":"ok","timestamp":1710176583012,"user_tz":-330,"elapsed":74904,"user":{"displayName":"Tanishq Trivedi","userId":"12574579820699221693"}},"outputId":"83c7cf56-5657-4c3c-987b-ca78571c7935"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09791e34afc84f7f94439c45c8c682f2"}},"metadata":{}}]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","train_model(vit_large, fsc, learning_rate=1e-5, num_epochs=15, batch_size=32, patience=5, stepSize=8)\n","\n","torch.save(vit_large.state_dict(), '/content/drive/MyDrive/data/Models/FSC22/vit_large.pth')"],"metadata":{"id":"iSm3mKiA3F6y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709840140592,"user_tz":-330,"elapsed":57621,"user":{"displayName":"Tanishq Trivedi","userId":"12574579820699221693"}},"outputId":"0efc2c05-5868-45c8-c876-b60d40fcaacc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","  Training Loss: 2.803943157196045\n","  Validation Loss: 2.9927961092728834, Accuracy: 14.57%\n","Epoch 2/15\n","  Training Loss: 2.1639981269836426\n","  Validation Loss: 2.3334745443784275, Accuracy: 32.10%\n","Epoch 3/15\n","  Training Loss: 1.9786603450775146\n","  Validation Loss: 1.7968014753781831, Accuracy: 42.22%\n","Epoch 4/15\n","  Training Loss: 1.0768325328826904\n","  Validation Loss: 1.5473997684625478, Accuracy: 52.35%\n","Epoch 5/15\n","  Training Loss: 1.2476134300231934\n","  Validation Loss: 1.5908198540027325, Accuracy: 55.06%\n","Epoch 6/15\n","  Training Loss: 0.9780671000480652\n","  Validation Loss: 1.5359266446186945, Accuracy: 57.04%\n","Epoch 7/15\n","  Training Loss: 0.5545846223831177\n","  Validation Loss: 1.5265280375113854, Accuracy: 57.78%\n","Epoch 8/15\n","  Training Loss: 0.3354269862174988\n","  Validation Loss: 1.4757359348810637, Accuracy: 62.22%\n","Epoch 9/15\n","  Training Loss: 0.0322713740170002\n","  Validation Loss: 1.3847225216718821, Accuracy: 64.44%\n","Epoch 10/15\n","  Training Loss: 0.03290538117289543\n","  Validation Loss: 1.3946421008843641, Accuracy: 62.96%\n","Epoch 11/15\n","  Training Loss: 0.012802514247596264\n","  Validation Loss: 1.3950245288702159, Accuracy: 62.47%\n","Epoch 12/15\n","  Training Loss: 0.01892516389489174\n","  Validation Loss: 1.392615244938777, Accuracy: 62.22%\n","Epoch 13/15\n","  Training Loss: 0.020473316311836243\n","  Validation Loss: 1.4041385925733125, Accuracy: 61.98%\n","Epoch 14/15\n","  Training Loss: 0.02258019708096981\n","  Validation Loss: 1.402234476346236, Accuracy: 62.47%\n","Early stopping after 5 epochs of no improvement.\n"]}]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/vit_large.pth', map_location=torch.device(device))\n","vit_large.load_state_dict(checkpoint)\n","\n","gen(fsc, vit_large, 'vit_large')"],"metadata":{"id":"P4kfmFdLnvtw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import timm\n","\n","def ret_pred(model, dataset):\n","    data_loader = DataLoader(dataset, batch_size=128)\n","    model = model.to(device)\n","    model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for batch_input, batch_target in data_loader:\n","            batch_input = batch_input.to(device)\n","            predictions = model(batch_input)\n","            all_predictions.append(predictions.argmax(dim=1))\n","\n","    all_predictions = torch.cat(all_predictions)\n","    return all_predictions\n","\n","def cal_ratio():\n","    attk_list = ['fgsm', 'bim', 'pgd', 'cw']\n","    adv_dir = 'vit_base'\n","\n","    vit_base = timm.create_model('vit_base_patch16_224.augreg2_in21k_ft_in1k', pretrained=True)\n","    vit_base.patch_embed.proj = nn.Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16))\n","    vit_base.head = nn.Linear(in_features=768, out_features=27, bias=True)\n","    torch.cuda.empty_cache()\n","    checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/vit_base.pth')\n","    vit_base.load_state_dict(checkpoint)\n","\n","    resnet18 = timm.create_model('resnet18.a1_in1k', pretrained=True)\n","    resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    resnet18.fc = nn.Linear(in_features=512, out_features=27, bias=True)\n","    torch.cuda.empty_cache()\n","    checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/resnet18.pth')\n","    resnet18.load_state_dict(checkpoint)\n","\n","    resnet50 = timm.create_model('resnet50.a1_in1k', pretrained=True)\n","    resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    resnet50.fc = nn.Linear(in_features=2048, out_features=27, bias=True)\n","    torch.cuda.empty_cache()\n","    checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/resnet50.pth')\n","    resnet50.load_state_dict(checkpoint)\n","\n","    mixer = timm.create_model('mixer_b16_224.goog_in21k_ft_in1k', pretrained=True)\n","    mixer.stem.proj = nn.Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16))\n","    mixer.head = nn.Linear(in_features=768, out_features=27, bias=True)\n","    torch.cuda.empty_cache()\n","    checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/mixer.pth')\n","    mixer.load_state_dict(checkpoint)\n","\n","    for attk in attk_list:\n","        h5_file_path = f'/content/drive/MyDrive/data/Target/FSC22/{adv_dir}/{attk}.h5'\n","        data_list = []\n","        label_list = []\n","\n","        with h5py.File(h5_file_path, 'r') as hf:\n","            # Iterate over the samples in the HDF5 file\n","            for sample_name in hf.keys():\n","                data = torch.tensor(hf[sample_name]['data'][:])\n","                label = hf[sample_name]['label'][()]\n","\n","                # Append data and label to lists\n","                data_list.append(data)\n","                label_list.append(label)\n","\n","        dataset_class = TensorDataset(torch.stack(data_list), torch.tensor(label_list))\n","        label_list = torch.tensor(label_list)\n","\n","        r18 = ret_pred(vit_base, dataset_class)\n","        unfooled = 0\n","        diff = 0\n","        same = 0\n","        for i in range(2025):\n","            if (r18[i] == label_list[i]):\n","                unfooled += 1\n","            else:\n","                same += 1\n","\n","        print (unfooled/2025, same/2025, diff/2025)\n","\n","        print(f'Ratio for {adv_dir}/{attk} dataset')\n","\n","        r50 = ret_pred(resnet18, dataset_class)\n","\n","        unfooled = 0\n","        diff = 0\n","        same = 0\n","        for i in range(2025):\n","            if (r50[i] == label_list[i]):\n","                unfooled += 1\n","            elif (r50[i] == r18[i]):\n","                same += 1\n","            else:\n","                diff += 1\n","\n","        print (unfooled/2025, same/2025, diff/2025)\n","\n","        vb = ret_pred(resnet50, dataset_class)\n","\n","        unfooled = 0\n","        diff = 0\n","        same = 0\n","        for i in range(2025):\n","            if (vb[i] == label_list[i]):\n","                unfooled += 1\n","            elif (vb[i] == r18[i]):\n","                same += 1\n","            else:\n","                diff += 1\n","\n","        print (unfooled/2025, same/2025, diff/2025)\n","\n","        m = ret_pred(mixer, dataset_class)\n","\n","        unfooled = 0\n","        diff = 0\n","        same = 0\n","        for i in range(2025):\n","            if (m[i] == label_list[i]):\n","                unfooled += 1\n","            elif (m[i] == r18[i]):\n","                same += 1\n","            else:\n","                diff += 1\n","\n","        print (unfooled/2025, same/2025, diff/2025)\n","\n","        del dataset_class\n","        del data_list\n","        del label_list\n","\n","cal_ratio()"],"metadata":{"id":"gihxaBHf-qCS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711145697984,"user_tz":-330,"elapsed":989811,"user":{"displayName":"Tanishq Trivedi","userId":"08401598246083797041"}},"outputId":"34cd8440-3d1e-4ca2-fbb1-14d1d6483e68"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.2325925925925926 0.7674074074074074 0.0\n","Ratio for vit_base/fgsm dataset\n","0.7091358024691358 0.017777777777777778 0.2730864197530864\n","0.7901234567901234 0.012345679012345678 0.19753086419753085\n","0.9279012345679012 0.01728395061728395 0.054814814814814816\n","0.1708641975308642 0.8291358024691358 0.0\n","Ratio for vit_base/bim dataset\n","0.8306172839506173 0.012345679012345678 0.15703703703703703\n","0.8874074074074074 0.005432098765432099 0.10716049382716049\n","0.9274074074074075 0.008888888888888889 0.0637037037037037\n","0.4380246913580247 0.5619753086419753 0.0\n","Ratio for vit_base/pgd dataset\n","0.8661728395061729 0.013333333333333334 0.12049382716049382\n","0.9130864197530865 0.007901234567901235 0.07901234567901234\n","0.9288888888888889 0.015308641975308642 0.05580246913580247\n","0.5032098765432099 0.49679012345679013 0.0\n","Ratio for vit_base/cw dataset\n","0.9432098765432099 0.0034567901234567903 0.05333333333333334\n","0.9496296296296296 0.006419753086419753 0.04395061728395062\n","0.9274074074074075 0.010864197530864197 0.06172839506172839\n"]}]},{"cell_type":"markdown","metadata":{"id":"UCs6JqIhqBiS"},"source":["# mixer"]},{"cell_type":"code","source":["import timm\n","mixer = timm.create_model('mixer_b16_224.goog_in21k_ft_in1k', pretrained=True)\n","mixer.stem.proj = nn.Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16))\n","mixer.head = nn.Linear(in_features=768, out_features=27, bias=True)"],"metadata":{"id":"WB7ttbPd3Vcx","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["7ec3fceb9c794f74b83bf971a9f5fd58","a6005edcc5774aba9aec5b340d6fb5dc","1607a54ed4a046c38fccb69323e8208d","cc4300313e8045598d6aa4defa5650f9","de52672d86e74a969b854d39c537def2","f547f582a2e04a8dab219abd0f1a927d","c08eb1950717460bb0d3589ca7e0bd39","dd8f9ca3a2604298ad95c23a1ce09219","202791bd8dee4521b4fc0392bdbe1ab2","8649480398534996a4bd367987793087","4f2139db5076437ea48d2e13aa1e3e51"]},"executionInfo":{"status":"ok","timestamp":1711139946255,"user_tz":-330,"elapsed":19222,"user":{"displayName":"Tanishq Trivedi","userId":"08401598246083797041"}},"outputId":"f6351b53-d065-4a28-f0a9-5a5e3e67f064"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/240M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ec3fceb9c794f74b83bf971a9f5fd58"}},"metadata":{}}]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","train_model(mixer, fsc, learning_rate=1e-4, num_epochs=12, batch_size=64)\n","\n","torch.save(mixer.state_dict(), '/content/drive/MyDrive/data/Models/FSC22/mixer.pth')"],"metadata":{"id":"Kq1r7vcg3Wq8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709660257469,"user_tz":-330,"elapsed":445016,"user":{"displayName":"Tanishq Trivedi","userId":"12574579820699221693"}},"outputId":"25027d5b-f991-4442-9b5e-06b3c7ea5e70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/12\n","  Training Loss: 2.8369762897491455\n","  Validation Loss: 3.023735216685704, Accuracy: 11.11%\n","Epoch 2/12\n","  Training Loss: 2.3608925342559814\n","  Validation Loss: 2.4845817429678783, Accuracy: 24.69%\n","Epoch 3/12\n","  Training Loss: 1.6835899353027344\n","  Validation Loss: 1.994707499231611, Accuracy: 40.49%\n","Epoch 4/12\n","  Training Loss: 1.4145755767822266\n","  Validation Loss: 1.7589199032102312, Accuracy: 45.93%\n","Epoch 5/12\n","  Training Loss: 1.4111098051071167\n","  Validation Loss: 1.5368074178695679, Accuracy: 54.32%\n","Epoch 6/12\n","  Training Loss: 0.71235191822052\n","  Validation Loss: 1.5113468851361955, Accuracy: 55.31%\n","Epoch 7/12\n","  Training Loss: 0.4558401107788086\n","  Validation Loss: 1.5051241431917464, Accuracy: 58.52%\n","Epoch 8/12\n","  Training Loss: 0.23333513736724854\n","  Validation Loss: 1.4426105533327376, Accuracy: 61.73%\n","Epoch 9/12\n","  Training Loss: 0.05255194753408432\n","  Validation Loss: 1.5103943347930908, Accuracy: 58.27%\n","Epoch 10/12\n","  Training Loss: 0.017816785722970963\n","  Validation Loss: 1.5024446078709193, Accuracy: 62.96%\n","Epoch 11/12\n","  Training Loss: 0.02149246074259281\n","  Validation Loss: 1.4621164117540633, Accuracy: 64.44%\n","Early stopping after 3 epochs of no improvement.\n"]}]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/mixer.pth')\n","mixer.load_state_dict(checkpoint)\n","\n","generate_adversarial(fsc, mixer, 'mixer')"],"metadata":{"id":"IOyxVQo2oANb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711141028768,"user_tz":-330,"elapsed":1073267,"user":{"displayName":"Tanishq Trivedi","userId":"08401598246083797041"}},"outputId":"7216c34a-96f3-4d09-ca6d-e63eaf7f0dfc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attack mode is changed to 'targeted(label)'.\n","Attack mode is changed to 'targeted(label)'.\n","Attack mode is changed to 'targeted(label)'.\n","Attack mode is changed to 'targeted(label)'.\n","started fgsm\n","0 - \n","\n","fgsm adv dataset for mixer\n","started bim\n","0 - \n","\n","bim adv dataset for mixer\n","started pgd\n","0 - \n","\n","pgd adv dataset for mixer\n","started cw\n","0 - \n","\n","cw adv dataset for mixer\n"]}]},{"cell_type":"code","source":["import timm\n","\n","def ret_pred(model, dataset):\n","    data_loader = DataLoader(dataset, batch_size=128)\n","    model = model.to(device)\n","    model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for batch_input, batch_target in data_loader:\n","            batch_input = batch_input.to(device)\n","            predictions = model(batch_input)\n","            all_predictions.append(predictions.argmax(dim=1))\n","\n","    all_predictions = torch.cat(all_predictions)\n","    return all_predictions\n","\n","def cal_ratio():\n","    attk_list = ['fgsm', 'bim', 'pgd', 'cw']\n","    adv_dir = 'mixer'\n","\n","    vit_base = timm.create_model('vit_base_patch16_224.augreg2_in21k_ft_in1k', pretrained=True)\n","    vit_base.patch_embed.proj = nn.Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16))\n","    vit_base.head = nn.Linear(in_features=768, out_features=27, bias=True)\n","    torch.cuda.empty_cache()\n","    checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/vit_base.pth')\n","    vit_base.load_state_dict(checkpoint)\n","\n","    resnet18 = timm.create_model('resnet18.a1_in1k', pretrained=True)\n","    resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    resnet18.fc = nn.Linear(in_features=512, out_features=27, bias=True)\n","    torch.cuda.empty_cache()\n","    checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/resnet18.pth')\n","    resnet18.load_state_dict(checkpoint)\n","\n","    resnet50 = timm.create_model('resnet50.a1_in1k', pretrained=True)\n","    resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    resnet50.fc = nn.Linear(in_features=2048, out_features=27, bias=True)\n","    torch.cuda.empty_cache()\n","    checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/resnet50.pth')\n","    resnet50.load_state_dict(checkpoint)\n","\n","    mixer = timm.create_model('mixer_b16_224.goog_in21k_ft_in1k', pretrained=True)\n","    mixer.stem.proj = nn.Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16))\n","    mixer.head = nn.Linear(in_features=768, out_features=27, bias=True)\n","    torch.cuda.empty_cache()\n","    checkpoint = torch.load('/content/drive/MyDrive/data/Models/FSC22/mixer.pth')\n","    mixer.load_state_dict(checkpoint)\n","\n","\n","    for attk in attk_list:\n","        h5_file_path = f'/content/drive/MyDrive/data/Target/FSC22/{adv_dir}/{attk}.h5'\n","        data_list = []\n","        label_list = []\n","\n","        with h5py.File(h5_file_path, 'r') as hf:\n","            # Iterate over the samples in the HDF5 file\n","            for sample_name in hf.keys():\n","                data = torch.tensor(hf[sample_name]['data'][:])\n","                label = hf[sample_name]['label'][()]\n","\n","                # Append data and label to lists\n","                data_list.append(data)\n","                label_list.append(label)\n","\n","        dataset_class = TensorDataset(torch.stack(data_list), torch.tensor(label_list))\n","        label_list = torch.tensor(label_list)\n","\n","        r18 = ret_pred(mixer, dataset_class)\n","        unfooled = 0\n","        diff = 0\n","        same = 0\n","        for i in range(2025):\n","            if (r18[i] == label_list[i]):\n","                unfooled += 1\n","            else:\n","                same += 1\n","\n","        print (unfooled/2025, same/2025, diff/2025)\n","\n","        print(f'Ratio for {adv_dir}/{attk} dataset')\n","\n","        r50 = ret_pred(resnet18, dataset_class)\n","\n","        unfooled = 0\n","        diff = 0\n","        same = 0\n","        for i in range(2025):\n","            if (r50[i] == label_list[i]):\n","                unfooled += 1\n","            elif (r50[i] == r18[i]):\n","                same += 1\n","            else:\n","                diff += 1\n","\n","        print (unfooled/2025, same/2025, diff/2025)\n","\n","        vb = ret_pred(resnet50, dataset_class)\n","\n","        unfooled = 0\n","        diff = 0\n","        same = 0\n","        for i in range(2025):\n","            if (vb[i] == label_list[i]):\n","                unfooled += 1\n","            elif (vb[i] == r18[i]):\n","                same += 1\n","            else:\n","                diff += 1\n","\n","        print (unfooled/2025, same/2025, diff/2025)\n","\n","        m = ret_pred(vit_base, dataset_class)\n","\n","        unfooled = 0\n","        diff = 0\n","        same = 0\n","        for i in range(2025):\n","            if (m[i] == label_list[i]):\n","                unfooled += 1\n","            elif (m[i] == r18[i]):\n","                same += 1\n","            else:\n","                diff += 1\n","\n","        print (unfooled/2025, same/2025, diff/2025)\n","\n","        del dataset_class\n","        del data_list\n","        del label_list\n","\n","cal_ratio()"],"metadata":{"id":"0m-2R19ukccz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711146702126,"user_tz":-330,"elapsed":1002123,"user":{"displayName":"Tanishq Trivedi","userId":"08401598246083797041"}},"outputId":"98e0710c-d6d4-4e57-b411-c1dc51fe601a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.08395061728395062 0.9160493827160494 0.0\n","Ratio for mixer/fgsm dataset\n","0.6474074074074074 0.023703703703703703 0.3288888888888889\n","0.7550617283950617 0.013333333333333334 0.23160493827160494\n","0.6785185185185185 0.034074074074074076 0.2874074074074074\n","0.037530864197530864 0.9624691358024692 0.0\n","Ratio for mixer/bim dataset\n","0.8967901234567901 0.0019753086419753087 0.10123456790123457\n","0.9244444444444444 0.0004938271604938272 0.07506172839506173\n","0.6854320987654321 0.007901234567901235 0.30666666666666664\n","0.08296296296296296 0.917037037037037 0.0\n","Ratio for mixer/pgd dataset\n","0.8711111111111111 0.0044444444444444444 0.12444444444444444\n","0.9145679012345679 0.0024691358024691358 0.08296296296296296\n","0.6879012345679012 0.01037037037037037 0.3017283950617284\n","0.4059259259259259 0.5940740740740741 0.0\n","Ratio for mixer/cw dataset\n","0.9422222222222222 0.0034567901234567903 0.05432098765432099\n","0.948641975308642 0.0024691358024691358 0.04888888888888889\n","0.6874074074074074 0.014814814814814815 0.29777777777777775\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"09791e34afc84f7f94439c45c8c682f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee0d811199d24ce1a0aac7b0efaefad5","IPY_MODEL_763c7f70ad32440f89e040379189ad8a","IPY_MODEL_c6de2825b71d4c3c8474876207b744c4"],"layout":"IPY_MODEL_09d1fa16c2a2461ebe69f851a4c8a282"}},"ee0d811199d24ce1a0aac7b0efaefad5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23f463bdaa8443dcb2a6bb95d0e9da57","placeholder":"​","style":"IPY_MODEL_9ff5442987de43688255a262ba3705f2","value":"model.safetensors: 100%"}},"763c7f70ad32440f89e040379189ad8a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1682d4d05ab64c5a818db3c033474048","max":1217334682,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3bb39db179a4402499f98ae8a87f71a4","value":1217334682}},"c6de2825b71d4c3c8474876207b744c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_652b9c1e70e84d30a7413ca0980e89ce","placeholder":"​","style":"IPY_MODEL_a118248bc08e46cdaa62f3e4492eba58","value":" 1.22G/1.22G [01:04&lt;00:00, 19.1MB/s]"}},"09d1fa16c2a2461ebe69f851a4c8a282":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23f463bdaa8443dcb2a6bb95d0e9da57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ff5442987de43688255a262ba3705f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1682d4d05ab64c5a818db3c033474048":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bb39db179a4402499f98ae8a87f71a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"652b9c1e70e84d30a7413ca0980e89ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a118248bc08e46cdaa62f3e4492eba58":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d39bbbfb9034d039a9bc7d2a138cd07":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_058d227039b54646a5fdf4f8369c30a2","IPY_MODEL_4f233774dce540ef944ebdcff00f7830","IPY_MODEL_0fadcf391ac9466284da6cc965848e5f"],"layout":"IPY_MODEL_6e30245847b647b0bb2c2beaa2eabb56"}},"058d227039b54646a5fdf4f8369c30a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8790c700cb67411db595461bf12f0dd3","placeholder":"​","style":"IPY_MODEL_4e7f869b68634a708a98ca4a936c8ba5","value":"model.safetensors: 100%"}},"4f233774dce540ef944ebdcff00f7830":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29b9cdf4a5544165a77899525be339a4","max":102469840,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c409612d371442c99f20a02e2bcea375","value":102469840}},"0fadcf391ac9466284da6cc965848e5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_baf92b9a1952411c85054c1e75294ff0","placeholder":"​","style":"IPY_MODEL_700cf46122af4e0e802ae77fd6836a0f","value":" 102M/102M [00:00&lt;00:00, 305MB/s]"}},"6e30245847b647b0bb2c2beaa2eabb56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8790c700cb67411db595461bf12f0dd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e7f869b68634a708a98ca4a936c8ba5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29b9cdf4a5544165a77899525be339a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c409612d371442c99f20a02e2bcea375":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"baf92b9a1952411c85054c1e75294ff0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"700cf46122af4e0e802ae77fd6836a0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68ba781c817c49fbacff636cf38f1d9e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_31fca44e8af04b48aad45e3620865789","IPY_MODEL_c8343049a1104017a656f74313ad61ae","IPY_MODEL_20ed308269ae4f769b1c00ad99fa764f"],"layout":"IPY_MODEL_6274a982039a4732bd75eb9567620095"}},"31fca44e8af04b48aad45e3620865789":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1da4a11647e94dd49bb3a9d7b74fc818","placeholder":"​","style":"IPY_MODEL_abf6397427da48d19a7b85ce98f91dcb","value":"model.safetensors: 100%"}},"c8343049a1104017a656f74313ad61ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a1bc31ab5094d0b9882788d793066f3","max":346284714,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73c298075759441f9a086265468e7fa0","value":346284714}},"20ed308269ae4f769b1c00ad99fa764f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8880251664a846339c24c744b795eb2b","placeholder":"​","style":"IPY_MODEL_4cde270a8a124b80872d38bb0640b254","value":" 346M/346M [00:01&lt;00:00, 278MB/s]"}},"6274a982039a4732bd75eb9567620095":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1da4a11647e94dd49bb3a9d7b74fc818":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abf6397427da48d19a7b85ce98f91dcb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a1bc31ab5094d0b9882788d793066f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73c298075759441f9a086265468e7fa0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8880251664a846339c24c744b795eb2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cde270a8a124b80872d38bb0640b254":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ec3fceb9c794f74b83bf971a9f5fd58":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a6005edcc5774aba9aec5b340d6fb5dc","IPY_MODEL_1607a54ed4a046c38fccb69323e8208d","IPY_MODEL_cc4300313e8045598d6aa4defa5650f9"],"layout":"IPY_MODEL_de52672d86e74a969b854d39c537def2"}},"a6005edcc5774aba9aec5b340d6fb5dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f547f582a2e04a8dab219abd0f1a927d","placeholder":"​","style":"IPY_MODEL_c08eb1950717460bb0d3589ca7e0bd39","value":"model.safetensors: 100%"}},"1607a54ed4a046c38fccb69323e8208d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd8f9ca3a2604298ad95c23a1ce09219","max":239536434,"min":0,"orientation":"horizontal","style":"IPY_MODEL_202791bd8dee4521b4fc0392bdbe1ab2","value":239536434}},"cc4300313e8045598d6aa4defa5650f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8649480398534996a4bd367987793087","placeholder":"​","style":"IPY_MODEL_4f2139db5076437ea48d2e13aa1e3e51","value":" 240M/240M [00:16&lt;00:00, 15.0MB/s]"}},"de52672d86e74a969b854d39c537def2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f547f582a2e04a8dab219abd0f1a927d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c08eb1950717460bb0d3589ca7e0bd39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd8f9ca3a2604298ad95c23a1ce09219":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"202791bd8dee4521b4fc0392bdbe1ab2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8649480398534996a4bd367987793087":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f2139db5076437ea48d2e13aa1e3e51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}